<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üá©üá™ Tutor Alem√°n - Conversaci√≥n Oral</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        .glass-effect {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(20px);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .listening-animation {
            animation: listening 1.5s ease-in-out infinite;
        }
        @keyframes listening {
            0%, 100% { transform: scale(1); box-shadow: 0 0 20px rgba(34, 197, 94, 0.3); }
            50% { transform: scale(1.05); box-shadow: 0 0 40px rgba(34, 197, 94, 0.6); }
        }
        .speaking-animation {
            animation: speaking 0.8s ease-in-out infinite;
        }
        @keyframes speaking {
            0%, 100% { transform: scale(1); box-shadow: 0 0 20px rgba(59, 130, 246, 0.3); }
            25% { transform: scale(1.03); box-shadow: 0 0 30px rgba(59, 130, 246, 0.5); }
            75% { transform: scale(0.97); box-shadow: 0 0 25px rgba(59, 130, 246, 0.4); }
        }
        .idle-animation {
            box-shadow: 0 0 15px rgba(168, 85, 247, 0.2);
        }
    </style>
</head>
<body class="min-h-screen bg-gradient-to-br from-blue-900 via-purple-900 to-indigo-900 text-white font-sans">
    
    <!-- Main Voice Interface -->
    <div class="min-h-screen flex flex-col items-center justify-center p-4">
        
        <!-- Header -->
        <div class="text-center mb-8">
            <div class="text-6xl mb-4">üá©üá™</div>
            <h1 class="text-4xl font-bold mb-2 bg-gradient-to-r from-yellow-400 to-orange-500 bg-clip-text text-transparent">
                Tutor de Alem√°n IA
            </h1>
            <p class="text-blue-200 text-lg">Conversaci√≥n oral inteligente</p>
        </div>

        <!-- Voice Interface -->
        <div class="glass-effect rounded-3xl p-8 max-w-md w-full text-center">
            
            <!-- Main Microphone Button -->
            <div class="relative mb-6">
                <button id="voiceButton" 
                        class="w-32 h-32 rounded-full bg-gradient-to-br from-purple-600 to-blue-600 
                               flex items-center justify-center text-4xl transition-all duration-300 
                               hover:scale-105 focus:outline-none focus:ring-4 focus:ring-purple-400 
                               idle-animation"
                        onclick="toggleVoice()">
                    üé§
                </button>
                
                <!-- Status Indicator -->
                <div id="statusIndicator" 
                     class="absolute -bottom-2 left-1/2 transform -translate-x-1/2 
                            px-3 py-1 rounded-full text-xs font-semibold bg-gray-800 text-gray-300">
                    Presiona para hablar
                </div>
            </div>

            <!-- Voice Status -->
            <div id="voiceStatus" class="mb-6">
                <p class="text-lg font-medium text-blue-200">
                    Habla en espa√±ol o alem√°n
                </p>
                <p class="text-sm text-gray-300 mt-1">
                    El tutor responder√° en alem√°n
                </p>
            </div>

            <!-- Voice Configuration -->
            <div class="space-y-4 mt-6">
                <div class="flex items-center justify-between">
                    <label class="text-sm text-gray-300">üîä Voz:</label>
                    <select id="voiceSelect" class="bg-gray-800 text-white rounded-lg px-3 py-1 text-sm">
                        <option value="natural">Natural</option>
                        <option value="professional">Profesional</option>
                        <option value="casual">Casual</option>
                    </select>
                </div>
                
                <div class="flex items-center justify-between">
                    <label class="text-sm text-gray-300">‚ö° Velocidad:</label>
                    <select id="speedSelect" class="bg-gray-800 text-white rounded-lg px-3 py-1 text-sm">
                        <option value="slow">Lenta</option>
                        <option value="medium" selected>Media</option>
                        <option value="fast">R√°pida</option>
                    </select>
                </div>
            </div>

            <!-- Connection Status -->
            <div id="connectionStatus" class="mt-6 text-xs text-gray-400">
                üîó Verificando conexi√≥n...
            </div>
        </div>

        <!-- Instructions -->
        <div class="mt-8 max-w-md text-center">
            <h3 class="text-lg font-semibold mb-3 text-yellow-400">üí° C√≥mo usar:</h3>
            <ul class="text-sm text-gray-300 space-y-2 text-left">
                <li>üé§ <strong>Presiona</strong> el micr√≥fono para empezar a hablar</li>
                <li>üó£Ô∏è <strong>Habla</strong> en espa√±ol o alem√°n</li>
                <li>ü§ñ <strong>Escucha</strong> la respuesta en alem√°n</li>
                <li>üìö <strong>Di</strong> "quiero practicar..." para juegos de rol</li>
                <li>üîÑ <strong>Contin√∫a</strong> la conversaci√≥n naturalmente</li>
            </ul>
        </div>
    </div>

    <script>
        // Configuration
        const API_BASE = 'https://tutor-aleman-api-v2-d4aabgcvapg0ekfj.westeurope-01.azurewebsites.net/api';
        
        // State
        let isListening = false;
        let isSpeaking = false;
        let recognition = null;
        let currentSessionId = 'session-' + Date.now();

        // DOM Elements
        const voiceButton = document.getElementById('voiceButton');
        const statusIndicator = document.getElementById('statusIndicator');
        const voiceStatus = document.getElementById('voiceStatus');
        const connectionStatus = document.getElementById('connectionStatus');
        const voiceSelect = document.getElementById('voiceSelect');
        const speedSelect = document.getElementById('speedSelect');

        // Initialize
        document.addEventListener('DOMContentLoaded', function() {
            initializeVoiceRecognition();
            checkBackendConnection();
        });

        // Check backend connection
        async function checkBackendConnection() {
            try {
                const response = await fetch(`${API_BASE}/hello`);
                if (response.ok) {
                    const data = await response.json();
                    updateConnectionStatus('‚úÖ Conectado al backend', 'text-green-400');
                } else {
                    updateConnectionStatus('‚ùå Error de conexi√≥n', 'text-red-400');
                }
            } catch (error) {
                console.error('Backend connection error:', error);
                updateConnectionStatus('‚ùå Backend no disponible', 'text-red-400');
            }
        }

        // Update connection status
        function updateConnectionStatus(message, className) {
            connectionStatus.textContent = message;
            connectionStatus.className = `mt-6 text-xs ${className}`;
        }

        // Initialize voice recognition
        function initializeVoiceRecognition() {
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'es-ES'; // Default to Spanish, will auto-detect

                recognition.onstart = function() {
                    console.log('Voice recognition started');
                    updateVoiceState('listening');
                };

                recognition.onresult = function(event) {
                    const transcript = event.results[0][0].transcript;
                    console.log('Transcript:', transcript);
                    processVoiceInput(transcript);
                };

                recognition.onerror = function(event) {
                    console.error('Voice recognition error:', event.error);
                    updateVoiceState('idle');
                    updateStatus('Error de reconocimiento de voz');
                };

                recognition.onend = function() {
                    console.log('Voice recognition ended');
                    if (isListening) {
                        updateVoiceState('idle');
                    }
                };
            } else {
                updateStatus('Reconocimiento de voz no disponible');
                voiceButton.disabled = true;
            }
        }

        // Toggle voice input
        function toggleVoice() {
            if (isListening) {
                stopListening();
            } else {
                startListening();
            }
        }

        // Start listening
        function startListening() {
            if (recognition && !isListening && !isSpeaking) {
                isListening = true;
                recognition.start();
            }
        }

        // Stop listening
        function stopListening() {
            if (recognition && isListening) {
                isListening = false;
                recognition.stop();
                updateVoiceState('idle');
            }
        }

        // Process voice input
        async function processVoiceInput(transcript) {
            updateVoiceState('processing');
            updateStatus('Procesando...');

            try {
                const response = await fetch(`${API_BASE}/voiceconversation`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        transcript: transcript,
                        language: 'auto-detect',
                        sessionId: currentSessionId
                    })
                });

                if (response.ok) {
                    const data = await response.json();
                    if (data.success) {
                        updateStatus('Respuesta recibida');
                        await speakGermanResponse(data.germanResponse);
                        
                        // Show explanation briefly if provided
                        if (data.explanation) {
                            setTimeout(() => {
                                updateStatus(data.explanation);
                                setTimeout(() => updateStatus('Presiona para hablar'), 3000);
                            }, 1000);
                        }
                    } else {
                        updateStatus('Error en la respuesta');
                    }
                } else {
                    updateStatus('Error de comunicaci√≥n');
                }
            } catch (error) {
                console.error('Communication error:', error);
                updateStatus('Error de conexi√≥n');
            }

            updateVoiceState('idle');
        }

        // Speak German response
        async function speakGermanResponse(text) {
            updateVoiceState('speaking');
            updateStatus('Hablando...');

            try {
                // Try Azure TTS first
                const response = await fetch(`${API_BASE}/speech/synthesize-url`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        text: text,
                        language: 'de-DE',
                        voice: voiceSelect.value,
                        speed: speedSelect.value
                    })
                });

                if (response.ok) {
                    const data = await response.json();
                    if (data.success && data.audioData) {
                        const audio = new Audio(`data:audio/wav;base64,${data.audioData}`);
                        audio.onended = () => updateVoiceState('idle');
                        await audio.play();
                        return;
                    }
                }
            } catch (error) {
                console.error('Azure TTS error:', error);
            }

            // Fallback to browser TTS
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'de-DE';
            utterance.rate = speedSelect.value === 'slow' ? 0.7 : speedSelect.value === 'fast' ? 1.3 : 1.0;
            utterance.onend = () => updateVoiceState('idle');
            speechSynthesis.speak(utterance);
        }

        // Update voice state
        function updateVoiceState(state) {
            voiceButton.className = voiceButton.className.replace(/listening-animation|speaking-animation|idle-animation/g, '');
            
            switch (state) {
                case 'listening':
                    voiceButton.classList.add('listening-animation');
                    voiceButton.innerHTML = 'üé§';
                    updateStatus('Escuchando...');
                    break;
                case 'processing':
                    voiceButton.innerHTML = 'ü§î';
                    updateStatus('Procesando...');
                    break;
                case 'speaking':
                    voiceButton.classList.add('speaking-animation');
                    voiceButton.innerHTML = 'üîä';
                    isSpeaking = true;
                    break;
                case 'idle':
                default:
                    voiceButton.classList.add('idle-animation');
                    voiceButton.innerHTML = 'üé§';
                    isListening = false;
                    isSpeaking = false;
                    updateStatus('Presiona para hablar');
                    break;
            }
        }

        // Update status
        function updateStatus(message) {
            statusIndicator.textContent = message;
        }
    </script>
</body>
</html>